{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterRCNNTrainer(nn.Module):\n",
    "    \"\"\"wrapper for conveniently training. return losses\n",
    "    The losses include:\n",
    "    * :obj:`rpn_loc_loss`: The localization loss for \\\n",
    "        Region Proposal Network (RPN).\n",
    "    * :obj:`rpn_cls_loss`: The classification loss for RPN.\n",
    "    * :obj:`roi_loc_loss`: The localization loss for the head module.\n",
    "    * :obj:`roi_cls_loss`: The classification loss for the head module.\n",
    "    * :obj:`total_loss`: The sum of 4 loss above.\n",
    "    Args:\n",
    "        faster_rcnn (model.FasterRCNN):\n",
    "            A Faster R-CNN model that is going to be trained.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, faster_rcnn):\n",
    "        super(FasterRCNNTrainer, self).__init__()\n",
    "\n",
    "        self.faster_rcnn = faster_rcnn\n",
    "        self.rpn_sigma = opt.rpn_sigma\n",
    "        self.roi_sigma = opt.roi_sigma 是在_faster_rcnn_loc_loss调用用来计算位置损失函数用到的超参数，\n",
    "\n",
    "        # target creator create gt_bbox gt_label etc as training targets. \n",
    "        #用于从20000个候选anchor中产生256个anchor进行二分类和位置回归，\n",
    "        #也就是为rpn网络产生的预测位置和预测类别提供真正的ground_truth标准\n",
    "        self.anchor_target_creator = AnchorTargetCreator()\n",
    "        #AnchorTargetCreator和ProposalTargetCreator是为了生成训练的目标（或称ground truth），\n",
    "        #只在训练阶段用到，ProposalCreator是RPN为Fast R-CNN生成RoIs，在训练和测试阶段都会用到。\n",
    "        #所以测试阶段直接输进来300个RoIs，而训练阶段会有AnchorTargetCreator的再次干预。\n",
    "        self.proposal_target_creator = ProposalTargetCreator()\n",
    "\n",
    "        self.loc_normalize_mean = faster_rcnn.loc_normalize_mean #(0., 0., 0., 0.)\n",
    "        self.loc_normalize_std = faster_rcnn.loc_normalize_std #(0.1, 0.1, 0.2, 0.2)\n",
    "\n",
    "        self.optimizer = self.faster_rcnn.get_optimizer() #SGD\n",
    "        # visdom wrapper\n",
    "        self.vis = Visualizer(env=opt.env)\n",
    "\n",
    "        # indicators for training status\n",
    "        self.rpn_cm = ConfusionMeter(2)#混淆矩阵\n",
    "        self.roi_cm = ConfusionMeter(21)\n",
    "        self.meters = {k: AverageValueMeter() for k in LossTuple._fields}  # average loss\n",
    "\n",
    "    def forward(self, imgs, bboxes, labels, scale):\n",
    "        \"\"\"Forward Faster R-CNN and calculate losses.\n",
    "        Here are notations used.\n",
    "        * :math:`N` is the batch size.\n",
    "        * :math:`R` is the number of bounding boxes per image.\n",
    "        Currently, only :math:`N=1` is supported.\n",
    "        Args:\n",
    "            imgs (~torch.autograd.Variable): A variable with a batch of images.\n",
    "            bboxes (~torch.autograd.Variable): A batch of bounding boxes.\n",
    "                Its shape is :math:`(N, R, 4)`.\n",
    "            labels (~torch.autograd..Variable): A batch of labels.\n",
    "                Its shape is :math:`(N, R)`. The background is excluded from\n",
    "                the definition, which means that the range of the value\n",
    "                is :math:`[0, L - 1]`. :math:`L` is the number of foreground\n",
    "                classes.\n",
    "            scale (float): Amount of scaling applied to\n",
    "                the raw image during preprocessing.\n",
    "        Returns:\n",
    "            namedtuple of 5 losses\n",
    "        \"\"\"\n",
    "        n = bboxes.shape[0] #获取batch个数\n",
    "        if n != 1: #本程序只支持batch_size=1\n",
    "            raise ValueError('Currently only batch size 1 is supported.')\n",
    "\n",
    "        _, _, H, W = imgs.shape\n",
    "        img_size = (H, W)\n",
    "\n",
    "        features = self.faster_rcnn.extractor(imgs) #vgg16 conv5_3之前的部分提取图片的特征\n",
    "        #通过RPN提取ROI相关的信息\n",
    "        rpn_locs, rpn_scores, rois, roi_indices, anchor = \\\n",
    "            self.faster_rcnn.rpn(features, img_size, scale)\n",
    "\n",
    "        # Since batch size is one, convert variables to singular form\n",
    "        bbox = bboxes[0]\n",
    "        label = labels[0]\n",
    "        rpn_score = rpn_scores[0]\n",
    "        rpn_loc = rpn_locs[0]\n",
    "        roi = rois\n",
    "\n",
    "\n",
    "        #调用proposal_target_creator函数生成sample roi（128，4）、gt_roi_loc（128，4）、gt_roi_label（128，1），\n",
    "        #RoIHead网络利用这sample_roi+feature为输入，输出是分类（21类）和回归（进一步微调bbox）的预测值，\n",
    "        #那么分类回归的groud truth就是ProposalTargetCreator输出的gt_roi_label和gt_roi_loc。\n",
    "        sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(\n",
    "            roi,\n",
    "            at.tonumpy(bbox),\n",
    "            at.tonumpy(label),\n",
    "            self.loc_normalize_mean,\n",
    "            self.loc_normalize_std)\n",
    "        # NOTE it's all zero because now it only support for batch=1 now\n",
    "        sample_roi_index = t.zeros(len(sample_roi))\n",
    "        roi_cls_loc, roi_score = self.faster_rcnn.head(\n",
    "            features,\n",
    "            sample_roi,\n",
    "            sample_roi_index)\n",
    "\n",
    "        # ------------------ RPN losses -------------------#\n",
    "        gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(\n",
    "            at.tonumpy(bbox),\n",
    "            anchor,\n",
    "            img_size)#输入20000个anchor和bbox，调用anchor_target_creator函数得到2000个anchor与bbox的偏移量与label\n",
    "        gt_rpn_label = at.totensor(gt_rpn_label).long()\n",
    "        gt_rpn_loc = at.totensor(gt_rpn_loc)\n",
    "        rpn_loc_loss = _fast_rcnn_loc_loss(\n",
    "            rpn_loc,\n",
    "            gt_rpn_loc,\n",
    "            gt_rpn_label.data,\n",
    "            self.rpn_sigma) #使用_smooth_l1_loss\n",
    "        #rpn_loc为rpn网络回归出来的偏移量（20000个），\n",
    "        #gt_rpn_loc为anchor_target_creator函数得到2000个anchor与bbox的偏移量，rpn_sigma=1.\n",
    "        \n",
    "        #rpn_score为rpn网络得到的（20000个）与anchor_target_creator得到的2000个label求交叉熵损失\n",
    "        rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-1)\n",
    "        _gt_rpn_label = gt_rpn_label[gt_rpn_label > -1] #在RPN不计算背景类\n",
    "        _rpn_score = at.tonumpy(rpn_score)[at.tonumpy(gt_rpn_label) > -1]\n",
    "        self.rpn_cm.add(at.totensor(_rpn_score, False), _gt_rpn_label.data.long())\n",
    "\n",
    "        # ------------------ ROI losses (fast rcnn loss) -------------------#\n",
    "        #roi_cls_loc为VGG16RoIHead的输出（128*84）， n_sample=128\n",
    "        n_sample = roi_cls_loc.shape[0]\n",
    "        roi_cls_loc = roi_cls_loc.view(n_sample, -1, 4) # roi_cls_loc=（128,21,4）\n",
    "        roi_loc = roi_cls_loc[t.arange(0, n_sample).long().cuda(), \\\n",
    "                              at.totensor(gt_roi_label).long()]\n",
    "        gt_roi_label = at.totensor(gt_roi_label).long() \n",
    "        gt_roi_loc = at.totensor(gt_roi_loc) #128个标签\n",
    "\n",
    "        roi_loc_loss = _fast_rcnn_loc_loss(\n",
    "            roi_loc.contiguous(),\n",
    "            gt_roi_loc,\n",
    "            gt_roi_label.data,\n",
    "            self.roi_sigma) #采用smooth_l1_loss\n",
    "        roi_cls_loss = nn.CrossEntropyLoss()(roi_score, gt_roi_label.cuda())\n",
    "\n",
    "        self.roi_cm.add(at.totensor(roi_score, False), gt_roi_label.data.long())\n",
    "\n",
    "        losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]\n",
    "        losses = losses + [sum(losses)]\n",
    "\n",
    "        return LossTuple(*losses)\n",
    "\n",
    "\n",
    "\n",
    "    def _smooth_l1_loss(x, t, in_weight, sigma):\n",
    "        sigma2 = sigma ** 2\n",
    "        diff = in_weight * (x - t)\n",
    "        abs_diff = diff.abs()\n",
    "        flag = (abs_diff.data < (1. / sigma2)).float()\n",
    "        y = (flag * (sigma2 / 2.) * (diff ** 2) +\n",
    "         (1 - flag) * (abs_diff - 0.5 / sigma2))\n",
    "        return y.sum()\n",
    "\n",
    "\n",
    "def _fast_rcnn_loc_loss(pred_loc, gt_loc, gt_label, sigma):\n",
    "    #输入分别为rpn回归框的偏移量与anchor与bbox的偏移量以及label\n",
    "    in_weight = t.zeros(gt_loc.shape).cuda()\n",
    "    # Localization loss is calculated only for positive rois.\n",
    "    # NOTE:  unlike origin implementation, \n",
    "    # we don't need inside_weight and outside_weight, they can calculate by gt_label\n",
    "    in_weight[(gt_label > 0).view(-1, 1).expand_as(in_weight).cuda()] = 1\n",
    "    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach(), sigma) #sigma设置为1\n",
    "    # Normalize by total number of negtive and positive rois.\n",
    "    loc_loss /= ((gt_label >= 0).sum().float()) # ignore gt_label==-1 for rpn_loss #除去背景类\n",
    "    return loc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    opt._parse(kwargs)\n",
    "#将调用函数时候附加的参数用，config.py文件里面的opt._parse()进行解释，然后获取其数据存储的路径，之后放到Dataset里面！\n",
    "    dataset = Dataset(opt)\n",
    "    dataset = Dataset(opt)\n",
    "    print('load data')\n",
    "#用VOCBboxDataset作为数据读取库，然后依次从样例数据库中读取图片出来，还调用了Transform(object)函数，完成图像的调整和随机反转工作！\n",
    "    dataloader = data_.DataLoader(dataset, \\\n",
    "                                  batch_size=1, \\\n",
    "                                  shuffle=True, \\\n",
    "                                  # pin_memory=True,\n",
    "                                  num_workers=opt.num_workers)\n",
    "    testset = TestDataset(opt)\n",
    "#将数据装载到dataloader中，shuffle=True允许数据打乱排序，num_workers是设置数据分为几批处理，同样的将测试数据集也进行同样的处理，然后装载到test_dataloader中！\n",
    "    test_dataloader = data_.DataLoader(testset,\n",
    "                                       batch_size=1,\n",
    "                                       num_workers=opt.test_num_workers,\n",
    "                                       shuffle=False, \\\n",
    "                                       pin_memory=True\n",
    "                                       )\n",
    "    faster_rcnn = FasterRCNNVGG16()\n",
    "    print('model construct completed')\n",
    "#设置trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "#将FasterRCNNVGG16作为fasterrcnn的模型送入到FasterRCNNTrainer中并设置好GPU加速    \n",
    "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "##接下来判断opt.load_path是否存在，如果存在，直接从opt.load_path读取预训练模型，然后将训练数据的label进行可视化操作  \n",
    "    if opt.load_path:\n",
    "        trainer.load(opt.load_path)\n",
    "        print('load pretrained model from %s' % opt.load_path)\n",
    "    trainer.vis.text(dataset.db.label_names, win='labels')\n",
    "    best_map = 0\n",
    "    lr_ = opt.lr\n",
    "#用一个for循环开始训练过程，而训练迭代的次数opt.epoch=14也在config.py文件中都预先定义好，属于超参数  \n",
    "    for epoch in range(opt.epoch):\n",
    "        trainer.reset_meters()\n",
    "        for ii, (img, bbox_, label_, scale) in tqdm(enumerate(dataloader)):\n",
    "            scale = at.scalar(scale)\n",
    "            #然后从训练数据中枚举dataloader,设置好缩放范围，将img,bbox,label,scale全部设置为可gpu加速\n",
    "            img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "             #调用trainer.py中的函数trainer.train_step(img,bbox,label,scale)进行一次参数迭代优化过程\n",
    "            trainer.train_step(img, bbox, label, scale)\n",
    "\n",
    "            if (ii + 1) % opt.plot_every == 0:\n",
    "                if os.path.exists(opt.debug_file):\n",
    "                    ipdb.set_trace() # 判断数据读取次数是否能够整除plot_every(是否达到了画图次数)，\n",
    "                    #如果达到判断debug_file是否存在，用ipdb工具设置断点，\n",
    "                    #调用trainer中的trainer.vis.plot_many(trainer.get_meter_data())将训练数据读取并上传完成可视化！\n",
    "\n",
    "\n",
    "                # plot loss\n",
    "                trainer.vis.plot_many(trainer.get_meter_data())\n",
    "\n",
    "                # plot groud truth bboxes\n",
    "                ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
    "                gt_img = visdom_bbox(ori_img_,\n",
    "                                     at.tonumpy(bbox_[0]),\n",
    "                                     at.tonumpy(label_[0]))\n",
    "                trainer.vis.img('gt_img', gt_img)\n",
    "                #将每次迭代读取的图片用dataset文件里面的inverse_normalize()函数进行预处理，将处理后的图片调用Visdom_bbox \n",
    "\n",
    "                # plot predicti bboxes\n",
    "                _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
    "                pred_img = visdom_bbox(ori_img_,\n",
    "                                       at.tonumpy(_bboxes[0]),\n",
    "                                       at.tonumpy(_labels[0]).reshape(-1),\n",
    "                                       at.tonumpy(_scores[0]))\n",
    "                trainer.vis.img('pred_img', pred_img)\n",
    "                #利用同样的方法将原始图片以及边框类别的预测结果同样在可视化工具中显示出来！\n",
    "\n",
    "                # rpn confusion matrix(meter)\n",
    "                trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n",
    "                # roi confusion matrix\n",
    "                trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n",
    "        eval_result = eval(test_dataloader, faster_rcnn, test_num=opt.test_num)\n",
    "        trainer.vis.plot('test_map', eval_result['map']) #调用trainer.vis.img将Roi_cm将roi的可视化矩阵以图片的形式显示出来\n",
    "        lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr'] #设置学习的learning rate\n",
    "        log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n",
    "                                                  str(eval_result['map']),\n",
    "                                                  str(trainer.get_meter_data()))\n",
    "        trainer.vis.log(log_info) #将损失学习率以及map等信息及时显示更新\n",
    "\n",
    "        if eval_result['map'] > best_map:\n",
    "            best_map = eval_result['map']\n",
    "            best_path = trainer.save(best_map=best_map)  #用if判断语句永远保存效果最好的map\n",
    "        if epoch == 9:\n",
    "            trainer.load(best_path)\n",
    "            trainer.faster_rcnn.scale_lr(opt.lr_decay)\n",
    "            lr_ = lr_ * opt.lr_decay #if判断语句如果学习的epoch达到了9就将学习率*0.1变成原来的十分之一\n",
    "\n",
    "        if epoch == 13: \n",
    "            break #判断epoch==13结束训练验证过程"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
